<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deeplearning.ai on Zaryab Muhammad Akram</title>
    <link>https://zaryabmakram.github.io/tags/deeplearning.ai/</link>
    <description>Recent content in deeplearning.ai on Zaryab Muhammad Akram</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 03 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://zaryabmakram.github.io/tags/deeplearning.ai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sequence Models</title>
      <link>https://zaryabmakram.github.io/blog/05-course5/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zaryabmakram.github.io/blog/05-course5/</guid>
      <description>Examples of Sequence Data Following are some input to output mapping of different types of data where Sequence Models are used: 
We can see that there are different types of sequence models. Where,
 input or output is a sequence both input and output are sequences (maybe of different lengths)  Notation Suppose we are working on Named Entity Recognition problem where given an input sequence of words, we want to predict where names are in the sequence.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Networks</title>
      <link>https://zaryabmakram.github.io/blog/deeplearning.ai/04-course4/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zaryabmakram.github.io/blog/deeplearning.ai/04-course4/</guid>
      <description>Computer Vision In Computer Vision problems, we have very large images (suppose 1000px \(\times\) 1000px) that means they have a very large input matrix X, in turn more weights. So, its gets very tough to get such a vast amount of data to prevent the model from overfitting. Also, it is computationally really slow.

Edge Detection using Convolutions 
The above mentioned example is of Vertical Edge Detection and works as follows:</description>
    </item>
    
    <item>
      <title>Structuring Machine Learning Projects</title>
      <link>https://zaryabmakram.github.io/blog/deeplearning.ai/03-course3/</link>
      <pubDate>Fri, 17 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zaryabmakram.github.io/blog/deeplearning.ai/03-course3/</guid>
      <description>When working on a machine learning problem, if you want to improve your algorithm&#39;s performance, there a a lot of choices to choose from. So its very important to filter out the best possible choices to try for your current problem.
Orthognalization The process of tuning one parameter/ hyperparameter at a time, such that its effect is independent to other parameters/ hyperparameters is called Orthognalization.
A machine learning project have several goals (as listed below).</description>
    </item>
    
    <item>
      <title>Improving Deep Neural Networks</title>
      <link>https://zaryabmakram.github.io/blog/deeplearning.ai/02-course2/</link>
      <pubDate>Wed, 15 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zaryabmakram.github.io/blog/deeplearning.ai/02-course2/</guid>
      <description>Train/ Dev/ Test Sets  Train Dev/ Cross-Validation Test   Small Data 70% 15% 15%   Big Data 98% (1 million) 1% (10,000) 1% (10,000)   In real world application, we often do not have enough data and our models are data hungry. Its alright to collect Train data from multiple sources (e.g. Web Scraping when actual application deals with photos takes from a phone camera) and can be different from distribution different from dev/ test sets.</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning</title>
      <link>https://zaryabmakram.github.io/blog/deeplearning.ai/01-course1/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://zaryabmakram.github.io/blog/deeplearning.ai/01-course1/</guid>
      <description>Deep Learning refers to training of Deep Neural Networks (neural networks with several hidden layers).
Deep Neural Networks basically automate the feature extraction step.

Neural Networks Takes input features, figures out functions to map it to output. Most commonly used function for this mapping is called ReLU (Rectified Linear Unit) function.

Supervised Learning with Neural Networks 
Examples    Network Type Usage Example Input (x) Output (y)     Simple NNN Housing Price Prediction House Features Price   Convolutional NN Image Classification Image Class (Cat/ Dog)   Recurrent NN Speech Recognition Audio Text    Structured vs.</description>
    </item>
    
  </channel>
</rss>